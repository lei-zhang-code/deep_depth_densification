{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Depth Densification (D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input depth sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I assume an input RGB image\n",
    "w, h = 640, 480\n",
    "\n",
    "# raw images\n",
    "I = None  # RGB image\n",
    "D = None  # ground truth depth map. invalid pixels are zero.\n",
    "M = None  # mask image, sensor sparse depth location\n",
    "\n",
    "# preprocessed input images\n",
    "S1 = None  # sparse depth map\n",
    "S2 = None  # distance transform\n",
    "\n",
    "\n",
    "def euclidean_traversal(image, pixel, cond):\n",
    "    \"\"\"Traversal image to find the closest pixel from starting point that satisfy a condition.\n",
    "    The search always starts at the next closest (in Hamming distance) in the NE, SE, NW, SW directions.\n",
    "    And search along the four edges of a diamond.\n",
    "    \n",
    "    image: numpy array\n",
    "    pixel: (x, y) tuple\n",
    "    cond: a function that operates on image(x, y) and returns True or False\n",
    "    \"\"\"\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise RuntimeError(\"D3::euclidean_traversal::image is not a numpy array.\")\n",
    "    if len(pixel) != 2:\n",
    "        raise RuntimeError(\"D3::euclidean_traversal::pixel is not a 2 element list or tuple.\")\n",
    "    w, h = image.shape[0], image.shape[1]\n",
    "    max_d_ham = max([pixel[0] + pixel[1], w - pixel[0] - 1 + pixel[1],\n",
    "                    pixel[0] + h - pixel[1] - 1, w - pixel[0] + h - pixel[1] - 2])\n",
    "    d_ham = 1  # hamming distance\n",
    "    while d_ham <= max_d_ham:\n",
    "        diff = 0.5 if d_ham % 2 == 1 else 0.0\n",
    "        while diff < d_ham / 2 + 0.1:  # search along the edge of the diamond, starting from center of the edge\n",
    "            for radx, rady in [(1, 1), (1, -1), (-1, 1), (-1, -1)]:  # the diamond has four edges\n",
    "                for tanx in [1, -1]:  # symmetrically search in both directions\n",
    "                    tany = - tanx * radx / rady\n",
    "                    x = pixel[0] + round((d_ham / 2) * radx + diff * tanx)\n",
    "                    y = pixel[1] + round((d_ham / 2) * rady + diff * tany)\n",
    "                    if x >= 0 and x < w and y >= 0 and y < h and cond(image[x, y]):\n",
    "                        return (x, y)\n",
    "            diff += 1.0\n",
    "        d_ham += 1\n",
    "    return (-1, -1)\n",
    "\n",
    "\n",
    "def correct_depth_and_sampling_maps(D, M):\n",
    "    \"\"\"For any pixel p in D and M, if D(p) == 0 and M(p) == 1, then find the nearest pixel p' and assign\n",
    "    M(p) = 0 and M(p') = 1.\n",
    "    \"\"\"\n",
    "    if M.shape != D.shape:\n",
    "        raise RuntimeError(\"D3::correct_depth_and_sampling_maps::sampling map dimension does not map depth map.\")\n",
    "    h, w = M.shape\n",
    "    for r in range(h):\n",
    "        for c in range(w):\n",
    "            if M[r, c] == 1 and D[r, c] == 0:\n",
    "                p = euclidean_traversal(D, (r, c), lambda x : x > 0)\n",
    "                if p == (-1, -1):\n",
    "                    raise RuntimeError(\"D3::correct_depth_and_sampling_maps::failed to find nearest valid depth.\")\n",
    "                M[r, c] = 0\n",
    "                M[p[0], p[1]] = 1\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "def euclidean_distance_transform(M):\n",
    "    \"\"\"Assumes that M is an mask image where M(x, y) == 1 means a point of interest, M(x, y) == 0 otherwise.\n",
    "    This is a multi-entry Breadth-First-Search (BSF) algo.\n",
    "    \n",
    "    Return:\n",
    "        dist: distance map\n",
    "        \n",
    "        orig: the nearest pixel map\n",
    "    \"\"\"\n",
    "    h, w = M.shape[0], M.shape[1]\n",
    "    orig = np.ones((h, w, 2)) * (-1)  # the closest interest point.\n",
    "    nexts = deque()\n",
    "    for r in range(h):\n",
    "        for c in range(w):\n",
    "            if M[r, c] == 1:\n",
    "                nexts.append(([r, c], [r, c]))  # next pixel and its potential nearest neighbor\n",
    "    while len(nexts) > 0:\n",
    "        n = nexts[0]\n",
    "        r, c = n[0]\n",
    "        r0, c0 = n[1]\n",
    "        r1, c1 = orig[r, c]\n",
    "        if [r1, c1] == [-1, -1] or np.linalg.norm([r - r1, c - c1]) > np.linalg.norm([r - r0, c - c0]):\n",
    "            orig[r, c] = [r0, c0]\n",
    "            dirs = [(0, 1), (1, 0), (-1, 0), (0, -1)]\n",
    "            for d in dirs:\n",
    "                rn, cn = r + d[0], c + d[1]\n",
    "                if rn >= 0 and rn < h and cn >= 0 and cn < w and np.any(orig[rn, cn] != [r0, c0]):\n",
    "                    nexts.append(([rn, cn], [r0, c0]))\n",
    "        nexts.popleft()\n",
    "    dist = np.zeros((h, w))\n",
    "    for r in range(h):\n",
    "        for c in range(w):\n",
    "            r0, c0 = orig[r, c]\n",
    "            dist[r, c] = np.linalg.norm([r - r0, c - c0])\n",
    "    return dist, orig\n",
    "                    \n",
    "    \n",
    "def compute_nearest_neighbor_depth(M, D):\n",
    "    \"\"\"Generate a depth map that has the same dimension as the input depth map D. Each pixel in the depth map\n",
    "    contains the depth of the nearest valid point in the sampling map M. M(x, y) == 1 means a pixel to sample.\n",
    "    \n",
    "    Note: this function assumes all D's pixels are valid, i.e. has positive depth values.\n",
    "    \"\"\"\n",
    "    if M.shape != D.shape:\n",
    "        raise RuntimeError(\"D3::compute_nearest_neighbor_depth::sampling map dimension does not map depth map.\")\n",
    "    h, w = M.shape[0], M.shape[1]\n",
    "    # get the nearest pixel map 'orig'\n",
    "    d, orig = euclidean_distance_transform(M)\n",
    "    dmap = np.zeros((h, w))\n",
    "    for r in range(h):\n",
    "        for c in range(w):\n",
    "            r0, c0 = orig[r, c]\n",
    "            dmap[r, c] = D[r0, c0]\n",
    "    return dmap\n",
    "\n",
    "\n",
    "def preprocess(I, D, M):\n",
    "    h, w = I.shape[0], I.shape[1]\n",
    "    if I.shape[2] != 3 or D.shape != (h, w) or M.shape != (h, w):\n",
    "        raise RuntimeError(\"D3::preprocess::Raw input images have wrong shapes.\")\n",
    "    correct_depth_and_sampling_maps(D, M)\n",
    "    S1 = compute_nearest_neighbor_depth(M, D)\n",
    "    S2 = euclidean_distance_transform(M)\n",
    "    return np.dstack([S1, S2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.zeros((20, 20))\n",
    "for r in range(0, 20, 4):\n",
    "    for c in range(0, 20, 4):\n",
    "        M[r, c] = 1\n",
    "d, _ = euclidean_distance_transform(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe3a71b6dd8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  0.  1.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 1.  1.  1.  0.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n",
      "[[ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  0.  1.]\n",
      " [ 1.  1.  0.  0.  0.]\n",
      " [ 1.  1.  1.  0.  1.]\n",
      " [ 1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.]]\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "D = np.ones((6, 5))\n",
    "M = np.zeros((6, 5))\n",
    "D[2, 3] = 0\n",
    "D[2, 4] = 0\n",
    "D[3, 3] = 0\n",
    "D[1, 3] = 0\n",
    "D[2, 2] = 0\n",
    "M[2, 3] = 1\n",
    "\n",
    "print(D)\n",
    "print(M)\n",
    "correct_depth_and_sampling_maps(D, M)\n",
    "print(D)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
